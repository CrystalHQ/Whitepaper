\begin{document}
CRYSTAL WHITE PAPER

\protect\hypertarget{_aendkubcvh4i}{}{}A decentralized governance and
reputation system for building collaborative communities

\section{\texorpdfstring{\protect\hypertarget{_y1rt8lapt7ck}{}{\protect\hypertarget{_Toc462050395}{}{}}ABSTRACT}{ABSTRACT}}\label{abstract}

We present a method to crowdsource expertise and technical tasks,
leading to better outcomes at a lower cost than traditional contracting.
This method naturally leads to credible reputation metrics that measure
an individual's values and skills, and can be further extended to
provide decentralized governance structures for organizations - a
mechanism we call reputarchy.

Two distinct reputation types are used to rank individuals: values and
skills. By using these reputations types in crowdsourced contests, we
can optimize results according to an arbitrary utility function and
update the individual's reputation accordingly. This reputation can be
transferred between communities without diluting its validity, allowing
for the creation of a universal reputation network.

Using cryptocurrencies and programmable blockchain smart contracts, a
well-designed competition marketplace can incentivize competition and
cooperation. This system, combined with several distinct contest types,
can be used to emulate most crowdsourced communities and marketplaces.
Such communities are a microcosm of our vision: \textbf{a global
collaborative network, representing every conceivable aspect of human
ingenuity and judgement.}

\section{\texorpdfstring{\protect\hypertarget{_dfwalwplhn0i}{}{\protect\hypertarget{_Toc462050396}{}{}}BACKGROUND}{BACKGROUND}}\label{background}

\subsection{CROWDSOURCING}\label{crowdsourcing}

The idea of paying large group of diverse individuals to solve a problem
has been around for hundreds of years. In 1714, the British government
offered Â£20,000 (equivalent to \textasciitilde{}\$3,500,000 today) to
the first individual that could create a method to determine accurate
longitude within half a degree\footnote{https://longitudeprize.org/history}.
This was one in a long line of instances where governments used
crowdsourcing contests to spur creativity. Nearly 50 years later in 1761
the problem was solved in two separate ways using two separate
measurement methods.

\subsection{WISDOM OF THE CROWDS}\label{wisdom-of-the-crowds}

Another large leap regarding crowdsourcing was made in 1907, by Francis
Galton. He realized that by taking the median guess of an ox's weight
among a diverse crowd of guessers, he could arrive at a number very
close to the true value of the ox's weight\footnote{Galton, F. (1907).
  "Vox populi". Nature, 75, pp. 450--451.}. This marked the beginning of
the realization that crowdsourcing could be used not just for
creativity, but for accuracy as well. This idea came to be known as the
wisdom of the crowd. Today, the concept of crowdsourcing and wisdom of
the crowd is used to power some of the most popular websites on the
internet, including Wikipedia, Reddit, and StackOverflow.

\subsection{INTERET REPUTATION}\label{interet-reputation}

In combination with the rise in crowdsourcing, there has been a surge of
interest in internet reputation metrics. One early example was eBay's
reputation system, which combined positive and negative feedback. eBay
moved show percent negative feedback in 2003\footnote{http://presnick.people.si.umich.edu/papers/postcards/PostcardsFinalPrePub.pdf},
a tacit recognition that their reputation system was having unintended
consequences. Similar realizations ultimately led to the development of
several new reputation algorithms designed to resist manipulation, with
one of the most popular, EigenTrust, being cited over 4,000
times\footnote{https://scholar.google.com/scholar?ion=1\&espv=2\&bav=on.2,or.r\_cp.\&biw=1366\&bih=667\&dpr=1\&um=1\&ie=UTF-8\&lr\&cites=4085997296011241419}.

\subsection{COMBINING REPUTATION AND
CROWDSOURCING}\label{combining-reputation-and-crowdsourcing}

As reputation and crowdsourcing began to evolve in tandem, game
theorists began wondering how they could be used together to elicit
better outcomes from the crowd. In 2011, the United States government
agency IARPA created the Aggregative Contingent Estimation project (ACE)
to answer such questions\footnote{https://www.iarpa.gov/index.php/research-programs/ace}.
One particular participant in ACE, the Good Judgement Project, was able
to achieve spectacular results, using civilians to outperform CIA
analysts by 30\%\footnote{http://www.npr.org/sections/parallels/2014/04/02/297839429/-so-you-think-youre-smarter-than-a-cia-agent}

\subsection{ETHEREUM}\label{ethereum}

In late 2015, Ethereum launched, a platform for creating smart contracts
on the blockchain. For the first time Decentralized applications became
as easy to build as standard web applications, and money was as easy to
program as any other piece of data. This represented a for the first
time a way to store reputation that was immutably linked to identities,
a feature previously found only in real life reputation. The
programmable money aspect also provided intriguing possibilities for
incentivized crowdsourcing.

While Ethereum represents a huge paradigm shift in the power to create
applications that don't have a centralized failure point, many have
pointed out that there are still fundamental limitations to the type of
decentralization that can be achieved\footnote{http://www.truthcoin.info/blog/contracts-oracles-sidechains/}.
In particular, critics have noted that any connection to external data
feeds, and any logic that requires human judgement, cannot be
decentralized purely with smart contracts. In addition to traditional
uses of crowdsourcing and reputation, Crystal can also be used for
decentralized applications that fill this hole.

\section{\texorpdfstring{\protect\hypertarget{_46tblw4991ix}{}{\protect\hypertarget{_Toc462050402}{}{}}SUMMARY
OF THE CRYSTAL
PLATFORM}{SUMMARY OF THE CRYSTAL PLATFORM}}\label{summary-of-the-crystal-platform}

\subsection{\texorpdfstring{\protect\hypertarget{_fd2e9lhrqplf}{}{\protect\hypertarget{_Toc462050403}{}{}}REPUTATION
MEASURES}{REPUTATION MEASURES}}\label{reputation-measures}

Crystal is a platform that aims to connect communities of experts on the
internet into a global network with quantifiable reputation scores for
both the values they exhibit as well as the skills they possess. Values
are ranked through a web-of-trust system, and are assumed to be
transitive meaning those whom exhibit values are assumed to be better at
judging those same values in others. Skills are ranked by a system of
competition where experts who perform well earn reputation from those
who perform poorly. In this way skills based-reputation measures the
relative skill-set of an expert compared to other experts.

\subsection{\texorpdfstring{\protect\hypertarget{_tzgn4l15n5pq}{}{\protect\hypertarget{_Toc462050404}{}{}}COMMUNITIES}{COMMUNITIES}}\label{communities}

Both values-based reputation and skills-based reputation exist in the
context of a \textbf{community}, which is defined as a group of people
who share similar values and objectives. These communities are a form of
organization that are self-organized around economic and social
incentives.

Checks and balances in the Crystal protocol encourage community
collaboration. Community core values are explicitly defined, but norms
for what those values mean are flexible and moderated by our value score
algorithm. Community members share in rewards and common good to the
extent that they are recognized by their peers through reputation and
are rewarded percentages of income based on outcomes derived from
contests and reputation score.

Crystal is unique in its ability for experts to transfer between
communities while maintaining a percentage of reputation in proportion
to how similar the two communities are to each other. This ability is
what allows Crystal to be a global measure of reputation, instead of a
series of one off metrics such as Reddit karma or STEEM power.

\subsection{\texorpdfstring{\protect\hypertarget{_bj4o04lm6m5u}{}{\protect\hypertarget{_Toc462050405}{}{}}CONTESTS}{CONTESTS}}\label{contests}

\textbf{Contests} are at the center of the Crystal protocol. In
practice, a contest creator (\textbf{client}) is seeking a good (service
or product) to be provided at the maximum level of quality and minimum
of cost possible in the marketplace. A contest can be seen as a task to
be fulfilled or challenge for experts to solve. The client will define
contests which describes what type of results the client desires, the
type of work involved and the bounty awarded for the winners. The tasks
are then offered to a community of experts, who are economically
incentivized to work as a team to generate the best submissions. Teams
utilize experts to analyze, inform, or rate creative output of value to
the client.

While this crowdsourced work can be traditional knowledge work such as
creating a website design, contests can also be for things not
traditionally considered crowdsourcing. Examples include incentivizing
writing social media posts that get upvoted or comments that are
considered insightful.

At the end of the decision making process, the contest reward is split
between all experts who helped complete the requirements of the contest,
with more value going to those experts who performed better.

\subsection{\texorpdfstring{\protect\hypertarget{_enss86h4mfgg}{}{\protect\hypertarget{_Toc462050406}{}{}}AN
EXAMPLE}{AN EXAMPLE}}\label{an-example}

As a concrete example of how Crystal could be used, let's take the
problem of finding experts who can write and audit smart contract code.
The hack of The DAO exposed this as an unsolved problem in the Ethereum
ecosystem. Using Crystal, one would create a ``smart contract security''
community. This community's reputation metrics and contests would then
serve as the backend for a number of important decentralized
applications (dapps) needed in the ecosystem such as:

\begin{itemize}
\item
  A dapp for hiring qualified people to code your custom smart contract.
\item
  A dapp for paid, crowdsourced smart contract security audits from
  qualified professionals
\item
  A dapp for decentralized reputation-based commit access to open source
  smart contract projects
\item
  A dapp to get advice from other smart contract coders on best
  practices (with the best advice from the most knowledgeable coders
  being ranked the highest)
\end{itemize}

Because each of these dapps would share the same reputation metrics and
crowdsourcing tools, each one would in turn improve the accuracy and
utility of the other dapps, and the ecosystem as a whole would benefit
from new dapps built on the platform in a way not seen with siloed
reputation metrics.

This example of a smart contract security community will be used
throughout the paper to explain the different parts of the Crystal
protocol.

\section{\texorpdfstring{\protect\hypertarget{_bwcjt25q5a7i}{}{\protect\hypertarget{_Toc462050407}{}{}}REPUTATION}{REPUTATION}}\label{reputation}

Crystal's base reputation layer is a general purpose reputation and
rating standard, which is a simple standard interface for accessing and
understanding reputation and ratings through smart contracts, similar to
the ERC20 token standard\footnote{https://github.com/ethereum/EIPs/issues/20}.
On top of this base layer we introduce two reputation metrics that
represent the two types of reputation typically used in real life
scenarios. One is for \textbf{values-based reputation}, in which
individual entities are being rated directly on how other people rate
them on community values like honesty or kindness. The second is for
\textbf{skills-based reputation}, in which an individual skills are
ranked based on the output of their skills such as the ability to write
forum posts or debug code.

\subsection{\texorpdfstring{\protect\hypertarget{_5mvgvpt00086}{}{\protect\hypertarget{_Toc462050408}{}{}}REPUTATION
AND RATINGS
STANDARD}{REPUTATION AND RATINGS STANDARD}}\label{reputation-and-ratings-standard}

Crystal's \textbf{reputation and ratings standard} is a set of common
functions that allow smart contracts to interact with ratings and
reputation in a consistent way, thus allowing them to keep the same
interface for their smart contract even if they change reputation
metrics.

The standard is simple, and is built on top of Crystal's notion of
communities. It gives several functions to return information about the
reputation or rating metric such as what it should be called, the type
of reputation it is (categorical or numerical), and how it should be
displayed (limits, units, etc.).

Any community can opt-in to having their members tracked using that
reputation metric, and a standard function will return the value of a
member's reputation within that community. Finally, if the reputation or
rating involves compiling ratings from users, it allows users to assign
ratings to each-other and content in consistent ways as well.

On top of this flexible system is built Crystal's foundational
reputation metrics: its values-based and skills-based reputation metric.

\subsection{\texorpdfstring{\protect\hypertarget{_4wg2txeesr4f}{}{\protect\hypertarget{_Toc462050409}{}{}}VALUES-BASED
REPUTATION}{VALUES-BASED REPUTATION}}\label{values-based-reputation}

Existing ratings and reputation systems such as Reddit are able to
classify the type of content that the community likes, but are not able
to identify the type of people that should hold influence in their
community according to community values. This means that any open
community that uses such a content centric system will be driven by
populist values and conflicts.

Crystal's values-based reputation is a fundamental type of reputation
that records and maps human values in a trust graph. Using values-based
reputation, communities can choose \textbf{core values} that they want
their members to hold. Core values influence things such as ratings or
stake in community decisions. We calculate a community `affinity' score
and create incentives for individuals to gain influence in the community
in alignment with the values of that community. Values-based reputation
eliminates trolling and provocative behavior and can enable application
of moral decision-making, such as deciding what content should not be
allowed on a platform.

\subsubsection{\texorpdfstring{\protect\hypertarget{_pa238j7lw1k0}{}{\protect\hypertarget{_Toc462050410}{}{}}VALUE
TAGS}{VALUE TAGS}}\label{value-tags}

\textbf{Value tags} are simple text representations of the value that
will be used in a values-based reputation rating. Each tag will be
registered in a global registry along with a hash of a longer free-form
description of the value. Long form descriptions can be fuzzy and
general, or precise enough to be used in a contractual agreement. For
the purpose of Crystal reputation calculation, tags and descriptions are
arbitrary and only have meaning in the context of the reputation trust
graph of the community. The Crystal algorithms will work with any
language, jargon, or concept.

Tags and descriptions can be created and registered at will, or existing
tags in the global registry can be reused if they are a good fit for a
community. While users can rate individuals and give personalized local
scores to any user for any value, global value scores are calculated
only for values which are rated as a core value by some community.

\subsubsection{\texorpdfstring{\protect\hypertarget{_6bm08b4j0oam}{}{\protect\hypertarget{_Toc462050411}{}{}}VALUE
SCORES}{VALUE SCORES}}\label{value-scores}

A user can have a \textbf{value score} for every value tag that exists
on the Crystal platform. They are a permanent record for the account
that earns them, and hold a value between 0 and 1. Value scores above .5
can generally be seen as having that value, while value scores below .5
can be seen as the reverse. Intermediate values can be seen as degrees
of that value that are had.

\paragraph{HOW VALUE SCORES WORK}\label{how-value-scores-work}

Value scores represent specific qualities that users of the system hold.
They're computed by combining versions of \textbf{Relative
Rank}\footnote{\href{http://dl.ifip.org/db/conf/ifiptm/ifiptm2007/Traupman07.pdf}{\emph{http://dl.ifip.org/db/conf/ifiptm/ifiptm2007/Traupman07.pdf}}}
and \textbf{EigenTrust++}\footnote{\url{http://www.cc.gatech.edu/~lingliu/papers/2012/XinxinFan-EigenTrust++.pdf}},
two Sybil-attack resistant versions of the \textbf{EigenTrust} algorithm
that normalizes based on the number of ratings each node has been given,
and incorporate the structure of feedback that users get.

\subparagraph{EIGENTRUST}\label{eigentrust}

The EigenTrust algorithm is based on the notion of transitive trust: A
peer will trust nodes trusted by those nodes it trusts (and so on).

The EigenTrust algorithm as described in \emph{Resisting Sybils in
Peer-to-peer Markets} - Traupman, et.al, is a four step process:

\[l_{\text{ij}} = sat(i,j)\  - \ unsat(i,j)\backslash n\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  This local trust score is then normalized over all local trust scores
  of nodes that this node has rated, such that all the local trust
  scores sum to 1, with any trust scores below 0 being dropped entirely,
  The \textbf{normalized trust score} \emph{c} between peers i and j is
  thus calculated:
\end{enumerate}

\(c_{\text{ij}} = \ \frac{max(l_{\text{ij}},0)}{\sum_{j}^{}{max(l_{\text{ij}},0)}}\)

\[t_{\text{ik}} = \sum_{j}^{}{c_{\text{ij}}c_{\text{jk}}}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  This process is continued outward, such that peer k becomes the new
  peer j. Eventually, the node has a complete view of the network. This
  can also be viewed as a probabilistic process, in which following
  nodes with higher \emph{t}'s will result in landing on a more
  trustworthy peer.
\end{enumerate}

The authors note that for networks with a sufficiently large set of
nodes, the aggregated local trust vector \emph{t} always converges to
the same number, regardless of which node \emph{i} it's calculated from.
This means that the trust vector \emph{t} represents a global notion of
trust that the network places on any given node.

START SETS

The authors also note that there are a few problems with the simple
algorithm above. Firstly, malicious nodes can create networks
specifically designed to increase the score count between each other, by
``trapping'' the probabilistic crawler mentioned above in a web of trust
links.

Secondly, if a node has not rated any peers (or has rated all peers
negatively) c\textsubscript{ij} will be undefined, making the algorithm
impossible to compute.

They solve both these problems with the notion of a trusted
``\textbf{start set}.'' This start set represents a set of trustworthy
peers that have not been compromised. To remove the chance of the
algorithm being trapped in a Sybil compromised network, they make sure
that every peer has at least some small amount of trust allocated
towards the start set, such that on any given step the algorithm can
exit the malicious network by returning to the start set.

If a node has not rated any peers in a positive way, then that peer is
treated as having implicitly given its trust to the start set, thus
avoiding dead ends in the network.

\subparagraph{RELATIVE RANK}\label{relative-rank}

Relative Rank is an algorithm that seeks to add additional
Sybil-resistance to the EigenTrust algorithm, while at the same time
making it more suitable for peer-to-peer markets. By transforming
EigenTrust's arbitrarily high trust vectors into a normalized value,
Relative Rank creates a clear decision procedure to determine if a peer
should be trusted or not within an interaction. The normalization
procedure also seeks to include negative feedback, in order to separate
dishonest users from users whom have simply not been ranked. In order to
create this procedure, Traupman first analyzed the behavior of
EigenTrust in marketplaces, then tried to determine a clear threshold in
the determination of whether a node was trustworthy or untrustworthy.
The results of this analysis is a five step procedure:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Run EigenTrust (as described above).
\item
  Separate start-set from non-start-set users
\item
  Separate non-start set members into groups according to how many
  \emph{k} feedbacks each member has received (both positive and
  negative) and in each group choose the member with the highest trust
  vector \emph{r\textsubscript{k}}
\item
  Find a line of best fit for all pairs (k, r\textsubscript{k}), and
  determine the slope \emph{m} and intercept \emph{b} of that line.
\item
  Define a non-start set node \emph{i}'s \textbf{relative rank} as
  \(\frac{r_{i} - b}{\text{mk}}\)
\item
  Repeat steps 3 - 5, but for the start
  set.\protect\hypertarget{_bchh8mw27fto}{}{}
\end{enumerate}

\subparagraph{EIGENTRUST++}\label{eigentrust-1}

EigenTrust++ suggests three ways to increase the attack resilience above
classic EigenTrust. Firstly, it adds the concept of ``feedback
similarity'' to its trust propogation neutralizing a class of attacks
that works by acting honestly, while rating dishonestly (in order to
increase your reputation relative to peers who both rate and act
honestly). Secondly, it incorporates information about how many
feedbacks a peer has received, allowing for peers with lots of negative
feedback to be treated differently than peers with low amounts of
feedback. Thirdly, it creates thresholds for trust propagation, reducing
the possibility that dishonest collectives can pass on reputation to
honest nodes, and vice versa.

For the purposes of this paper, we utilize EigenTrust++'s feedback
similarity rating, and linear threshold, but don't use it's
incorporation of feedback number. This is because we include a different
normalization procedure based on feedback number, described above in the
section on RelativeRank.

FEEDBACK SIMILARITY

EigenTrust++ notes that a peer can mailiciously attack the network by
always acting honestly when interacting when interacting with high
reputation peers, but interacting dishonestly in other situations. It
solves this problem by creating a ``feedback similarity'' metric which
allows honest nodes to detect this type of behavior, and propagate less
trust to nodes that engage in it. It has an added bonus for our
algorithm, as it captures the notion of subjective values -- a node will
trust other nodes that see the value in the same way that it does.

This is incorporated into EigenTrust with the following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Average all local trust ratings together, between all nodes \emph{w}
  that nodes \emph{u} and \emph{v} have both rated
\end{enumerate}

\[\text{tr}\left( u,w \right) = \ \frac{\sum_{i = 1}^{n}{\text{tr}_{i}(u,w)}}{n}\]

\[\text{tr}\left( v,w \right) = \ \frac{\sum_{i = 1}^{n}{\text{tr}_{i}(v,w)}}{m}\]

Where \emph{n} and \emph{m} are the number of transactions between the
two peers.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Compute the similarity between two nodes \emph{u} and \emph{v} by
  computing the sample standard deviations of all node ratings that they
  have in common.
\end{enumerate}

\[\text{sim}\left( u,v \right) = 1 - \ \sqrt{\frac{\sum_{w \in comn(u,v)}^{}{(tr\left( u,w \right) - tr\left( v,w \right))}^{2}}{n + m}}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \protect\hypertarget{_1tg0egos6sa6}{}{}Divide similarity among all
  nodes \emph{m} that have a similarity score from node \emph{u} to
  create a normalized feedback score.
\end{enumerate}

\[\text{feed}\left( u,v \right) = \frac{sim(u,v)}{\sum_{i = 1}^{R(m)}{sim(u,m)}}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Define feedback credibility as a metric that weights each normalized
  trust score cij by each normalized feedback score feed(i,j).
\end{enumerate}

\[fc(i,j) = c_{\text{ij}} \bullet feed(i,,j)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Redefine local trust value lij in terms of it's normalized counterpart
  that includes feedback credibility.
\end{enumerate}

\[l_{\text{ij}} = \left\{ \begin{matrix}
\frac{max(fc\left( i,j \right),0)}{\sum_{m = 1}^{R(i)}{max(fc\left( i,m \right),0)}}\begin{matrix}
\text{if}\sum_{m = 1}^{R(i)}{\max{\left( \text{fc}\left( i,m \right),0 \right)\  \neq 0}}\  \\
\text{otherwise} \\
\end{matrix} \\
0 \\
\end{matrix} \right.\ \]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Redefine initial aggregated trust using the new definition of local
  trust given above.
\end{enumerate}

\[t_{\text{ij}} = \ \sum_{k}^{}l_{\text{ik}}c_{\text{kj}}\]

TRUST PROPOGATION

While EigenTrust counts both feedback similarity as well as trust level
equally for the score itself, it recommends that you weight feedback
similarity higher when determining trust propagation. It uses the
following calculation with the constant Î² (a real number between 0 and
1) to weight the trust accordingly.

\[\text{weighttrust}\left( i,j \right) = \left( 1 - \ \beta \right) \bullet \ c_{\text{ji}} + \ \beta \bullet sim(j,i)\]

The authors of the Eigentrust paper suggest that Î² should equal .85.

PROPOGATION THRESHOLDS

\subparagraph{VALUE RANK }\label{value-rank}

Value rank, our algorithm for calculating the values that an individual
holds, makes two minor changes to the original relative rank algorithm.
It makes local ratings more granular, and it allows for multiple start
sets.

GRANULAR LOCAL RATINGS

In the original relative rank algorithm, feedback is binary, and
interactions could be rated only positive (plus one) or negative (minus
one). While this makes sense for the original implementation of
EigenTrust, in which a peer either gave the correct data or did not, it
does not allow for the nuance that comes with arbitrary values, such as
deciding the level of kindness that a user showed. In relative rank,
this also means that there is less distinction between individual
ratings, because of the high correlation between \emph{r} and \emph{k}.
For this reason, individual ratings are given as a decimal value between
positive one and negative one, allowing for more granularity in every
interaction. By multiplying the final relative rank by 2 and subtracting
1, individuals can also get a clear intuition for what a relative rank
score means - an individual rating of \emph{-0.3} means the same thing
as a relative rank score of \emph{-0.3.}

MULTIPLE START SETS

In the original relative rank, a single start set is used. A related
algorithm is also given called RAW which allows for personalized start
sets. In value rank, multiple start sets can be created, one for every
community that ranks that value as their core value. This captures the
notion of values as relative interpretations that exist within community
context, while still striking a good balance with computational cost.

\paragraph{COMMUNITY LEVEL VALUE
SCORES}\label{community-level-value-scores}

The Relative Rank algorithm used to calculate value scores has the
ability to calculate different value scores based on what group of
initial "trusted users" it calculates from. This is ideal for growing
out a global trust graph while allowing individuals to build value
scores faster in the community they're a part of. The ultimate goal for
value-based reputation in Crystal is to build a global trust graph that
spans a diverse network of communities and scales to planetary levels.

\subparagraph{COMMUNITY CORE VALUES}\label{community-core-values}

In Crystal, each community can choose to create its own set of
\textbf{core values}, and for each of those core values can define one
or more community members they consider paragons of that value. This
becomes the initial start set from which the trust graph grows. As new
members on-board and participate in Novice Matches they are rated by the
existing members thereby populating new nodes in the trust graph.

\subparagraph{AFFINITY SCORE}\label{affinity-score}

As individuals begin to get rated in a community's core values, we begin
to get a sense of their affinity for the community. We can
mathematically represent this affinity by averaging their score along
all core values. We call this average of all community core values for a
specific user that user's \textbf{affinity score.} The affinity score is
used throughout the Crystal platform to make sure that individuals who
have influence in the community are in alignment with the values of that
community.

\paragraph{VALUE SCORES IN ACTION}\label{value-scores-in-action}

Let's imagine how value scores might be used in our smart contract
security community.

Firstly, the community as a whole would choose a set of core values. For
each set of core values the community would choose a start set of people
they considered paragons of that value. Let's assume for examples sake
that the core values the community chose were honesty, integrity, and
thoroughness. These core values would then ensure that new members
trying to become smart contract experts had to have an affinity with
those values, through use of the affinity score. For users who were
already on the Crystal platform, their influence on the governance of
the community would be limited based on their affinity score.

Secondly, value scores could be used in our crowdsourced commit access
Dapp to make sure that those who participated matched the values of that
open source project. For instance, if an open source project valued
compromise, they could limit the influence of any given expert's ability
to push through a commit based on how high that expert's ``willingness
to compromise'' value score was.

Finally, value score could be used in a subjective way in our smart
contract coder hiring dapp to choose candidates that would mesh with a
given project's value system. One can imagine first filtering by
candidates who share the hirer's values, and then sorting by
skills-based reputation tokens to find the most talented candidate
within that group.

\subsection{\texorpdfstring{\protect\hypertarget{_fwpxhowvyax}{}{\protect\hypertarget{_Toc462050412}{}{}}SKILLS-BASED
REPUTATION}{SKILLS-BASED REPUTATION}}\label{skills-based-reputation}

\textbf{Skills-based reputation} is the second foundational type of
reputation. While values-based reputation answers the question ``What
type of person are you?'' skills-based reputation answers the question
``What are you good at?''

This is a hard question to answer because it's incredibly hard to judge
unrealized talent. To solve this problem, Crystal transforms the ``What
are you good at?'' question to an easier question: ``How good was your
performance?'' Thus skills-based reputation in Crystal is based on the
ratings of the performance that an expert produces.

This raises a secondary question: Who rates the performance? To answer
this question, Crystal creates two additional types of meta-skills based
reputation: The skill of explaining why a performance is good
(critiquing), and skill that can rank how good a performance is
(grading).

\paragraph{GRADING AND CRITIQUING AS
FORECASTING}\label{grading-and-critiquing-as-forecasting}

When the meta-skills of grading and critiquing are used before the
outcome of an event is known (example: a battle plan is critiqued and
graded before the battle), they correspond to the ability to both
understand and predict the future.

This type of crowdsourcing-based forecasting combined with reputation
has been shown to outcompete established experts like CIA analysts by
30\%\footnote{http://www.npr.org/sections/parallels/2014/04/02/297839429/-so-you-think-youre-smarter-than-a-cia-agent},
and is comparable with the accuracy of prediction markets when the
proper algorithms are used\footnote{http://papers.ssrn.com/sol3/papers.cfm?abstract\_id=2660628}.

It is this ranking of forecasting ability that gives these meta-skill
reputation tokens (clarity tokens and accuracy tokens) equal value to
the primary skill-based token creativity tokens.

\subsubsection{\texorpdfstring{\protect\hypertarget{_t7frhn7cs0ly}{}{\protect\hypertarget{_Toc462050413}{}{}}REPUTATION
TOKENS}{REPUTATION TOKENS}}\label{reputation-tokens}

To represent the three different skills that experts may have within
their domain, Crystal splits reputation into three separate tokens.
These tokens represent three separate ways you can enter a contest.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  You can create content for the contest. This will earn you a type of
  reputation called \textbf{creativity tokens}.
\item
  You can critique the content in the contest, this will earn you a type
  of reputation called \textbf{clarity tokens}.
\item
  You can rate the content in the contest, this will earn you a type of
  reputation called \textbf{accuracy tokens}.
\end{enumerate}

\paragraph{CREATIVITY TOKENS}\label{creativity-tokens}

To earn creativity tokens one must generate new submissions to the
contest. If those submissions perform well according to the rules of the
contest, one will earn more creativity tokens. Submissions don't have to
be in the form of text. An idea could just as easily be presented in the
form of code, blueprints, or mockups - allowing for creativity tokens to
be used for arbitrary crowdsourcing applications.

\paragraph{ACCURACY TOKENS}\label{accuracy-tokens}

To earn accuracy tokens, one must evaluate how well submissions meet the
variables that go into the utility function specified by the client.
Evaluators provide probability estimates among all these variables for
the options generated by creatives. This allows the client to make the
decision-theoretically optimal decision.

\paragraph{CLARITY TOKENS}\label{clarity-tokens}

To earn clarity tokens, one must explain the pros and cons of different
submissions. You can think of these pros and cons as analogous to
comments on traditional crowdsourcing sites. However, these explanations
do not just have to be in text, and can be in arbitrary media depending
on the application. While the client gets to see all explanations by
every critic, the explanations are only shown to evaluators on a
probabilistic basis to enable linear regression analysis of the
explanation's impact. This allows clarity tokens to get redistributed to
those who most help the predictors make accurate predictions.

\paragraph{CRYSTAL CLEAR TOKENS }\label{crystal-clear-tokens}

Crystal Clear tokens are a Crystal Tokens that have not yet been
converted to tokens marked for a particular community, token type, and
contest (Colored Crystal). Crystal Clear can be sold as assets for
purposes of fundraising for the platform or given out as rewards for
referring active users to the platform. Crystal Clear tokens are special
in that they are not used as a measure of reputation in themselves.
Crystal Clear can be transformed by any individual at any time, into any
of the tokens above, in any community - subject to that individual's
expected token score for that type of token (as explained below). They
are also the only tokens that can be used originally to start
communities. The market price for Crystal Clear tokens should
approximate the going market rate for the highest priced Colored Crystal
tokens in the marketplace at any given time.

\paragraph{TRANSFORMING AND TRANSFERRING
TOKENS}\label{transforming-and-transferring-tokens}

One of the current problems with internet based reputation is that
accounts can be easily sold if not tied to strong identities, thus
making it impossible to know if reputation was earned or simply
purchased.

Crystal solves this problem by allowing the tokens used for reputation
to be transformed into sellable tokens, while making the reputation
metric itself unassailable. The way it does this is by incentivizing the
sale of or transformation of reputation tokens only to people who
deserve those tokens. By doing this, it gives people honest ways to
profit from reputation tokens they no longer have a use for.

\subparagraph{SIMILARITY SCORE}\label{similarity-score}

In Crystal, we measure similarity by assuming that communities are
similar if people that have more of a token in community \emph{a} also
have more of a token in community \emph{b.} This relationship is easily
calculated using an asymmetric measurement of Pearson Correlation, which
is described below. The following example assumes that you are trying to
move coins from community \emph{a} to community \emph{b}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Take the set of all users who's tokens \emph{t} in community \emph{b}
  are greater than 0.
\item
  For each of these users, create a set of pairs
  (\emph{t\textsubscript{a},t\textsubscript{b}}) for the tokens they
  hold in communities \emph{a} and \emph{b}.
\item
  Calculate the Pearson Correlation Coefficient for all \emph{n} pairs
\end{enumerate}

\[r(a,b) = \frac{n\sum_{i = 1}^{n}{\left( t_{\text{na}}{\bullet t}_{\text{nb}} \right) - (\sum_{}^{}{t_{\text{na}})(\sum_{}^{}{t_{\text{nb}})}}}}{\sqrt{(n\sum_{}^{}{\left( t_{\text{na}} \right)^{2} - {(\sum_{}^{}{t_{\text{na}})}}^{2})(n\sum_{}^{}{\left( t_{\text{nb}} \right)^{2} - {(\sum_{}^{}{t_{\text{nb}})}}^{2})}}}}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  For all \emph{r} below 0, set the similarity score to 0.
\end{enumerate}

\[\text{simscore}\left( a,b \right) = \ \left\{ \begin{matrix}
r(a,b) \\
0 \\
\end{matrix} \right.\ \begin{matrix}
\text{\ \ \ \ \ }\text{if\ r}\left( a,b \right) > 0 \\
\text{otherwise} \\
\end{matrix}\]

Note that this similarity score is asymmetric because t \textgreater{} 0
for community \emph{b,} but t â¥ 0 for community \emph{a}. This has the
effect of correcting the imbalanced similarity rate of large
communities, which likely will have high many high similarity rates
simply due to chance.

\subparagraph{EXCHANGE RATE}\label{exchange-rate}

In a typical currency, the exchange rate is determined by relative
demand for two different ideas. Crystal, being a reputation token, has
an entirely different notion of exchange rate that mimics how reputation
works in real life. Crystal creates a simple asymmetric metric that
shows how ``similar'' two different skills are, and then uses this
equation to create an exchange rate when converting from one to the
other. This is done using linear regression, as described below,
assuming the user is exchanging tokens from community \emph{j} to
community \emph{k}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  For all people that hold more than 0 tokens in community \emph{j or
  k}, create the pair (\emph{tÂ­\textsubscript{j},t\textsubscript{k})}
  where each \emph{t} is the amount of tokens those people have
\item
  Use linear regression to calculate the line of best fit for all
  \emph{n} pairs. Plug in the amount of tokens \emph{t} to get the naÃ¯ve
  rate.
\end{enumerate}

\[\text{naiverate}\left( j,k,t \right) = \frac{n\sum_{i = 1}^{n}{\left( t_{\text{ji}} \bullet t_{\text{ki}} \right) - \sum_{}^{}{t_{j} \bullet}\sum_{}^{}t_{k}}}{\sqrt{n(\sum_{}^{}{{t_{j}}^{2}) - ({\sum_{}^{}t_{j})}^{2}}}\  \bullet \sqrt{n(\sum_{}^{}{{t_{k}}^{2}) - ({\sum_{}^{}t_{k})}^{2}}}\ } \bullet \left( t \right) + \frac{\sum_{}^{}{t_{k} - \frac{n\sum_{i = 1}^{n}{\left( t_{\text{ji}} \bullet t_{\text{ki}} \right) - \sum_{}^{}{t_{j} \bullet}\sum_{}^{}t_{k}}}{\sqrt{n(\sum_{}^{}{{t_{j}}^{2}) - ({\sum_{}^{}t_{j})}^{2}}}\  \bullet \sqrt{n(\sum_{}^{}{{t_{k}}^{2}) - ({\sum_{}^{}t_{k})}^{2}}}\ } \bullet (\sum_{}^{}{t_{j})}}}{n}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Multiply the exchange rate by the similarity score, which lowers the
  output of the linear regression when it applies less:
\end{enumerate}

\[\text{exchrate}\left( j,k,t \right) = simscore(j,k) \bullet naiverate(j,k,t)\backslash n\]

\subparagraph{TOKEN DEACTIVATION}\label{token-deactivation}

Token deactivation serves as a mechanism to make it hard for people to
use their tokens to claim reputation in an expertise they don't have.
Inactive tokens cannot be used in contests. The only way for tokens to
get reactivated is through earning the same type of tokens in contests.
For every token of the same type earned, an inactive token is
reactivated. The flipside is that for every token of the same type lost
within a contest, you lose a corresponding deactivated token. These lost
deactivated tokens are then given back to the community to be
distributed through novice matches. What this means is that owning
deactivated tokens causes you to be able to both win and lose tokens
twice as fast. This encourages users to only be willing to hold
deactivated tokens that they know they have expertise in.

\subparagraph{\texorpdfstring{\protect\hypertarget{_r8gpsdl6g5v5}{}{\protect\hypertarget{_9330mvdpn09}{}{}}TRANSFERRING
WITH EXPECTED
TOKENS}{TRANSFERRING WITH EXPECTED TOKENS}}\label{transferring-with-expected-tokens}

When calculating how many tokens should be deactivated during the sale
or transfer of a token, the user's entire token portfolio, along with
the exchange rate, is used to calculate an ``expected tokens'' value for
the community they're moving into. Every token a user holds in all
communities (except the community for which tokens are being bought) is
multiplied by its percent similarity with the community token being
bought. These numbers are then averaged together to calculate the
`expected tokens' that the user should have in a given community. The
expected tokens \emph{e} are computed for all \emph{n} communities the
user \emph{u} belongs to with the following equation:

\[exptok(u,\ c)\  = \ \frac{\sum_{i = 1}^{n}{exchrate({j_{\text{iu}},\ c)t}_{\text{iu}}}}{n}\]

Where \emph{s} equals the similarity score between community \emph{j}
and the desired community \emph{c} and \emph{t} equals the number of
tokens in community \emph{i}.

Any tokens purchased that exceed this number are deactivated.

This discourages whales in a community from buying or transforming
tokens to cement their advantage, because they are likely already above
their allotment of expected tokens. It also discourages non-experts from
buying influence in contests, because their expected tokens are likely
very low. What it encourages is experts from similar communities who
don't want to sacrifice tokens through transformation to buy tokens from
communities they should do well in. This transfer of crypto-reputation
to people who deserve that reputation in real life is the exact behavior
we'd like to encourage.

TRANSFORMING TOKENS USING SIMILARITY SCORE

When transforming tokens from one community to another (or one contest
type to another), a slightly different procedure is used. The similarity
between the two communities is used to figure out how many tokens are
deactivated \emph{in each transfer}.

This procedure holds up to the point at which the user reaches their
expected tokens for a community. After that point, 100\% of transformed
tokens are deactivated.

\[\text{transf}\left( j,k,t \right) = \left\{ \begin{matrix}
\text{simscore}\left( j,k \right) \bullet t \\
0 \\
\end{matrix} \right.\ \frac{\text{\ \ \ \ simscore}\left( j,k \right) > 0\ and\ exptok\left( j,k,t \right) < t_{k}\text{\ \ }}{\text{otherwise}}\ \]

This procedure preserves the incentives of transferred tokens, and adds
the additional incentive to transform tokens into tokens which represent
similar skills. This allows skill tokens to take on a price related the
value of that skill in the marketplace, instead of being merely an
average of every skill in the market.

EXPECTED TOKENS IN ACTION

{[}needs reworking{]}

\subparagraph{NORMALIZING SCORES AFTER TRANSFER AND
TRANSFORMATION}\label{normalizing-scores-after-transfer-and-transformation}

When coins are transferred, all scores are normalized using the
equivalent of a fake contest that involves spreading the coins among all
the participants, then having the transferring participant's score being
raised just enough to win an equal amount of coins from every other
participant. Because of the use of weighted averages in almost all
cases, this is a relatively simple procedure that only has to be
recalculated when users are entering contests. In the case of Bayesian
scoring, the entire calibration curve will simply be shifted the
appropriate amount, thus not changing the shape of the curve itself.

\subsubsection{\texorpdfstring{\protect\hypertarget{_ifdcb2xo8ouo}{}{\protect\hypertarget{_Toc462050414}{}{}}CRYSTAL
CONTESTS}{CRYSTAL CONTESTS}}\label{crystal-contests}

In Crystal, the only way to earn skills-based reputation tokens is by
entering into a contest. A contest is a community level event in which
you're competing against all others experts in the community to create
the best content. Contests can be repeating, such as trying to create
the best content for the day in a Reddit-like website. They can also be
one time, such as a company making a contest in where experts compete to
create a new product line.

\subparagraph{CONTEST STANDARD}\label{contest-standard}

All contests are implemented as smart contracts that follow a predefined
standard. The contest standard determines how coins are redistributed in
expert contests, initially distributed in novice matches, and how the
protocol reacts to coin transfers and transformations to that contest
type. This allows new crowdsourcing applications with varied needs to
incorporate Crystal reputation into their own unique contest types that
are not covered by standard Crystal contests. It also allows for various
contest types to be experimented with, such as the algorithms provided
by fellow crypto-reputation platforms Backfeed, Augur, Steemit, and
Synereo.

\paragraph{MATHEMATICAL BUILDING BLOCKS
}\label{mathematical-building-blocks}

All contest types built in to Crystal use essentially the same basic
mathematical building blocks. The Client provides a \textbf{utility
function}, which is a mathematical representation of their preferences.
Then, experts try to fulfill those preferences. Their submissions are
ranked on each preference using a \textbf{probability distribution},
which is a mathematical representation of their uncertainty about how
the submissions should be ranked according to the client's criteria.
These probability distributions might be over a \textbf{binary outcome,}
spread over several \textbf{categorical options}. Or be trying to
pinpoint a number in a \textbf{scalar outcome.} The probability
distributions are combined using \textbf{pooling,} which is a
mathematical tool to turn multiple probability estimates into one
combined estimate, and oftentimes made more accurate with extremizing. A
\textbf{monte-carlo method} is then used on these final probability
distributions as they fit within the utility function. A monte-carlo
method can be thought of as a guess-and-check method that a computer
uses. Finally, a \textbf{bayesian scoring function} is used, comparing
the final values to the values each user came up with. A bayesian
scoring function is a way to compare an individual's performance to some
idealized notion of performance over time. The results of this bayesian
scoring function are used to redistribute tokens. \emph{Appendix A}
defines these terms further, and provides resources to learn more.

\paragraph{CONTEST TYPES}\label{contest-types}

There are three separate types of contests in Crystal. We chose three
because we found that with just these three types, we could emulate all
of the crowdsourcing websites that we've currently evaluated. The three
contest types are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Metrics Contests}: Contests in which experts compete against
  some objective criteria provided by an oracle.
\item
  \textbf{Consensus Contests}: Contests in which experts compete to
  please or agree with their peers
\item
  \textbf{Judging Contests}: Contests in which experts are evaluated
  along subjective criteria by a judge.
\end{enumerate}

\subparagraph{METRICS CONTESTS}\label{metrics-contests}

Metrics contests are contests in which experts' probabilities are
ultimately judged based on real world data provided by an oracle. This
oracle could be a data feed provided by a provider like Oraclize
it\footnote{http://www.oraclize.it/}, or could even be some sort of
Schelling-point oracle\footnote{https://blog.ethereum.org/2014/03/28/schellingcoin-a-minimal-trust-universal-data-feed/}
such as a Crystal consensus contest. This is analogous to crowdsourcing
sites like the forecasting site gjopen.com, and the data science site
kaggle.com, which both use objective real-word criteria to rate their
experts.

CREATIVITY TOKENS

Creativity tokens in metrics contests are awarded based on experts
trying to create something which meets some objective criteria. They may
be creating products which maximize sales, creating code which minimizes
errors, or creating a chess strategy that maximizes chance of winning.

To redistribute the creativity tokens in a metrics contest, we use the
monte-carlo simulation that plugs probability distributions into the
utility function to determine how much expected utility each submission
generates. The utility for each solution is divided by the total utility
for all solutions and weighted by the amount of creativity tokens in the
contest (in comparison to the average amount of creativity tokens in a
contest). This is then used to create a weighted running mean for the
user, and tokens are distributed by this weighted running mean. The
creativity tokens \emph{t for} expert \emph{e} are calculated as:

{[}needs work, still need to put formula{]}

\[t_{e} = \frac{\sum_{i = 1}^{}(\frac{x_{e}}{x_{a}} \cdot t_{c})}{t_{a}}\]

ACCURACY TOKENS

Accuracy tokens in a metrics contest are awarded based on how well the
reality of a metric matches the expert's forecast. They may be
predicting the sales of a product, the frequency of errors in a
codebase, or the chance of a particular chess strategy leading to a win.
Accuracy tokens are awarded for every accuracy along every variable that
goes into a utility function. When the oracle reports the actual
results, we use the Bayesian scoring rule to determine if the user's
answer improves or hurts their calibration and their final Bayes score
is then used to redistribute Accuracy tokens among all users.

{[}needs algorithm{]}

CLARITY TOKENS

Clarity tokens in a metrics contest are awarded based on how much an
expert's comments on a particular submission helped other experts
generate accurate predictions of performance. They may be explaining why
a particular product will sell, showing where a codebase has errors, or
analyzing why different chess strategies will work.

To redistribute Clarity tokens, we first have to only show explanations
to a probabilistic subset of predictors. To minimize information lost,
users who already have more Clarity tokens have more of a chance of
their explanations being shown. Finally, we use linear regression to
determine how much impact each comment had on the bayesian score of
those predictors. These coefficients are then weighted by the amount
Clarity tokens in the contest, and a weighted running mean of all the
contests the user participated in is created. Tokens are redistributed
based on the final spread of all these scores.

{[}needs algorithm{]}

METRICS CONTESTS IN ACTION

Let's imagine how a metric contests could be used in our smart contract
security community.

One place they could definitely be used would be in the auditing of
smart contracts. For instance, a simple utility function could be
defined which included the rating of the Dapp on the Dapp store in one
year's time, and the amount of bugs found in the code in one year's
time, using a clear definition of how serious something had to be to be
considered a bug, and an oracle such as a Crystal consensus contest.

Smart contract creators would then earn Creativity tokens by creating
the most highly rated, bug free code, Smart contract critiquers could
earn Clarity tokens by pointing out bugs in the code and problems with
the design that would cause it to be rated poorly, and Smart Contract
evaluators would predict the number of bugs and rating on the Dapp
store. At the end of a year, once these values were known, reputation
tokens would be distributed accordingly.

\subparagraph{CONSENSUS CONTESTS}\label{consensus-contests}

Consensus contests measure community agreement on a subject. They can be
used as Schelling-point oracles similar to Augur's reputation metric, to
rank options against each other based on their community acceptance as
in Steemit, or to gauge a communities take on intangibles such as rating
how beautiful a piece of artwork is. This is analogous to crowdsourcing
sites such as the tech advice site StackExchange, which use consensus
based mechanisms to rank their participants.

CREATIVITY TOKENS

Creativity tokens in consensus contests are awarded based on meeting a
utility function just like metrics contests, with the difference being
that there's no ultimate reality that decides the outcome. They can be
earned by creating a forum post that the community likes, creating a
mission statement that the community agrees is good, or writing code
that the community determines is beautiful.

ACCURACY TOKENS

Accuracy tokens in consensus contests are awarded based on how well an
expert's opinion matches the weighted opinion of a community. They may
be trying to determine how much the community likes a forum post, rating
how good a mission statement, or trying to determine the level of beauty
of a piece of code.

To redistribute Accuracy tokens, the main scoring tool is to take the
final pooled distributions, and, and compute the information gain
between those distributions and the experts initial distribution, as an
inverse correlation between the information gain and the final score.
This is then weighted by the amount of Accuracy tokens in the contest,
and computed as a running mean among all other contests that expert has
participated in. The coins are redistributed based upon these final
numbers.

{[}needs algorithm{]}

CLARITY TOKENS

Clarity tokens in consensus contests are awarded based on how well an
expert's explanation helps other experts minimize their information
gain. They may be trying to explain the merits of a forum post, debate
the finer points of a mission statement, or giving reasons that a given
piece of code is beautiful.

Clarity tokens are redistributed much the same way as they are in
metrics contest, except that instead of the Bayesian score, the inverse
information gain is used as the second variable in the correlation. This
score is then weighted by total Clarity tokens in the contest, and
computed as a running mean among all contests that user has participated
in. These scores are used as the basis for distribution of Clarity
tokens.

{[}needs algorithm{]}

CONSENSUS CONTESTS IN ACTION

Let's imagine how a consensus contest might be used in our smart
contract security community

Firstly, one can imagine a StackExchange-like forum where programmers
could discuss the creation of smart contracts. The entire site would be
a daily consensus contest to ask the best question, and the questions
themselves would be contests to determine the top answer. One would get
Creativity tokens for asking and answering questions, Accuracy tokens
for voting on them, and Clarity tokens for commenting. Instead of a
single up or down vote, voting would be more like range voting, in which
you could allocate however many votes to every question or answer you
voted on, and the entire distribution of your votes would be interpreted
as a categorical distribution, with your amount of votes indicating
something akin to your probability estimate that this is the best
question.

Secondly, as mentioned above, consensus contests could be used as a kind
of decentralized oracle for metrics contests, using the game theoretic
mechanism of Schelling Score. If you made a consensus contest for
instance around how many bugs had been found in a particular contract
over the past year, you'd be incentivized to count the obvious bugs that
everyone else would also count, and everyone would most likely cluster
around the same set of numbers at roughly the same probabilities. This
allows you to have metrics contests without any worry of centralization.

\subparagraph{JUDGING CONTESTS}\label{judging-contests}

Judging contests are subjective contests. If this option is chosen, a
judge ultimately rates the ideas (although voters can still help to
eliminate options and guide the judges). Pre-judgement scores are also
weighted by similarity between the judge and the experts, in order to
show the judge the proper weighting before they make their decision(s).
This is analogous to crowdsourcing sites such as the design site
99designs, which use subjective criteria to choose winners.

CREATIVITY TOKENS

Creativity tokens in judging contests are awarded based on experts
trying to produce content that the judge approves of. They may be trying
to create a design that pleases the judge, tell a joke that the judge
thinks is funny, or creating a post that a judge likes.

The redistribution of Creativity tokens is nearly identical to metrics
contests with one important exception. Instead of an oracle reporting on
an objective criteria, the judge reports on a subjective criteria.

ACCURACY TOKENS

Accuracy tokens in judging contests are awarded based on the experts
having the same criteria as an individual judge. They may be trying to
guess how much a design will please the judge, predict what a judge
would find funny, or forecast which post a judge would like.

Accuracy tokens in judging contests are redistributed based on one of
two criteria. In one criteria, the judge chooses a single winner, and
the Bayesian scoring rule is used to score accuracy tokens. The weight
of any given contest on the ultimate Bayes score of the participant is
weighted based on the Honesty score of a particular client, in order to
neutralize collusion. In the other criteria, the judge rates all
submissions, and the inverse information gain between the judge's
ratings and each expert's rating is used as the criteria.

CLARITY TOKENS

Clarity tokens in judging contests are awarded based on how well an
expert's explanation helps an expert please the judge. They may be
trying to explain the merits of a forum post, say why a particular
design is good, or giving reasons that a given piece of code is
beautiful.

Clarity tokens are redistributed much the same way as they are in
metrics contest and consensus contests.

JUDGING CONTESTS IN ACTION

Let's look at how judging contests might play out in our smart contract
security community.

While security seems like a mostly objective goal, with little room for
subjectivity, it's nonetheless possible to imagine a scenario in which
you might want to include a judging criterion in a contest. One example
might be for decentralized commit access to an open source smart
contract. While the ultimate goal might be full decentralization, it
might be pertinent to start out with a long time contributor acting as
judge, looking at things like coding standards and code clarity to make
their judgements. Only once community members had learned the judge's
tastes (and those who didn't eliminated from the pool) would the commit
access become fully decentralized with a consensus contest.

\subparagraph{EARNING NEW TOKENS THROUGH
CONTESTS}\label{earning-new-tokens-through-contests}

In addition to whatever reward was posted into a contest by a client,
experts also earn newly minted tokens by participating in Crystal
contests. These tokens are given proportionately to each contest based
on how many expert tokens are in that contest, and then proportionately
to each expert based on their score within that contest. Half of newly
minted tokens go to experts through expert contests, and half go to
novices through participation in novice matches (explained below).

\paragraph{ONBOARDING USERS IN
CRYSTAL}\label{onboarding-users-in-crystal}

Crystal has two distinct ways to earn these three tokens:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Novice Matches}, involving contestants who are working to earn
  newly minted crystal colored tokens.
\item
  \textbf{Expert Contests}, involving expert contestants gaining and
  losing tokens from each other.
\end{enumerate}

By separating the two ways to earn tokens, we have a smooth path for
which users can work towards earning money on the platform while
learning community norms and improving their skills.

\subparagraph{NOVICE MATCHES}\label{novice-matches}

Novice Matches allow new users to grow their affinity score and earn
Crystal tokens as a new member of a community. They're scored very
differently from expert contests, and must use a separate Sybil defense
mechanism because they can't use token ownership as a proxy. Every
contest contract can specify a corresponding novice match protocol, and
if so, will have a mirrored version of all expert contests using that
protocol. The general format of novice matches is as follows

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Only accounts without Crystal Tokens in that community can participate
  in the matches
\item
  All accounts must complete a nominal task such as a captcha to
  participate in matches for that month.
\item
  Only accounts with an affinity score of .5 can earn token in those
  matches.
\item
  Novice Matches are played out over the course of a month. At the end
  of the month, all qualified participants are given a percentage of the
  newly minted Crystal tokens, based on their performance in the novice
  matches that month.
\end{enumerate}

For Crystal's three contest types, the Novice Matches play out very
similarly to how the expert contests described above play out. The
difference being that instead of coins being used to determine the level
of someone's influence for Accuracy tokens, an influence limiter
function using a reputation score is used before the Bayesian Scoring
function as described by Resnik and Sami in their paper The Influence
Limiter: Provably Manipulation-Resistant Recommender Systems\footnote{P.
  Resnick and R. Sami, ``The influence limiter: Provably manipulation
  resistant recommender systems,'' in ACM RecSys '07, pp. 25--32, ACM,
  2007}.

The central insight for using an influence limiter is the same as that
used to rate consensus contests - a user should raise their reputation
if weighing them more would have created a smaller information gain in
previous predictions.

{[}needs algorithm{]}

Because there's no notion of pooling influence to create Sybil attacks
for creativity tokens or clarity tokens, those are scored much the same
as described for expert contests, with the amount of coins in the expert
contest being used for the weight, and everyone starting with some
nominal score like .001.

\subparagraph{EXPERT CONTESTS}\label{expert-contests}

Once an expert has accumulated some tokens, they can enter expert
contests. Expert contests are the only way in which experts can be paid
by Clients on the system, and are used as the basis for which winning
entries are presented to the Client.

All expert contests in Crystal follow the same basic format. First,
experts compete to meet the goals of the campaign as defined by the
Client. Based on how well the expert does, they may earn reputation from
other experts, or lose reputation to those experts. Then, based on how
much reputation they have when the contest closes, they earn a portion
of the fee that the Client paid for the contest deliverables.

Because influence in expert contests is limited by tokens, they already
have an effective Sybil defense, which holds below 50\% of contest
participants being Sybil accounts.

\paragraph{CAMPAIGNS VS CONTESTS}\label{campaigns-vs-contests}

From the Client's perspective a campaign is a single unified event in
which people compete to deliver a multi-faceted solution for the Client.
However, from the perspective of experts looking to earn Clarity tokens
and Accuracy tokens, each campaign will be broken up into a number of
different contests centered on each variable in the utility function. In
this way contest participants function as a team, utilizing creatives,
evaluators and critics from varying communities, each of whom are
specialized in their expertise. The results from all these contests are
then combined using a monte-carlo simulation, to give the client the
answer, task, or submission that best fits their overall criteria.

\section{\texorpdfstring{\protect\hypertarget{_ikggzbtiqopr}{}{\protect\hypertarget{_Toc462050415}{}{}}GOVERNANCE}{GOVERNANCE}}\label{governance}

Crystal's base governance layer at its core is a simple standard that
can be extended with smart contracts to encompass arbitrary governance
protocols. This standard defines governance for each individual Crystal
Community, as well as governance at the protocol level, called
CrystalDAO, which defines global rules about interactions between and
within every community.

On top of this standard we build two primary forms of governance. The
first we've named value-weighted voting, which is a democratic voting
mechanism that gives more weight to those who offer more value to the
system, as well as those who hold the values the system prizes. The
second we've named reputarchy, which extends value-weighted voting by
allowing those with higher weights to set the goals and directions, then
allows experts who have proven they're good at fulfilling those goals to
make decisions.

For individual communities, governance is decided at the point of
creation. The plan for the CrystalDAO is to start with value-weighted
voting, and build in incentives (similar in spirit to Ethereum's
difficulty bomb\footnote{http://ethereum.stackexchange.com/questions/3779/when-will-the-difficulty-bomb-make-mining-impossible})
to switch to reputarchy as the ecosystem of expert communities matures.

\subsection{\texorpdfstring{\protect\hypertarget{_5f0ybphephcy}{}{\protect\hypertarget{_Toc462050416}{}{}}GOVERNANCE
STANDARD}{GOVERNANCE STANDARD}}\label{governance-standard}

Crystal's governance standard is a simple flexible standard that allows
for the suggestion of proposals, the execution of actions, and the
ability to assign these powers through a system of hierarchical
permissions. Because proposals and actions can be arbitrary code or
function calls, and permissions can be assigned to smart contract, this
system allows for a standard interface that any governance protocol can
be plugged into. Nexusdev's dappsys framework\footnote{https://github.com/nexusdev/dappsys}
already includes most of this functionality, and we're currently
investigating the possibility of adapting it for our purposes.

\subsection{\texorpdfstring{\protect\hypertarget{_1ovimyyiwxnm}{}{\protect\hypertarget{_Toc462050417}{}{}}VALUE-WEIGHTED
VOTING}{VALUE-WEIGHTED VOTING}}\label{value-weighted-voting}

Value-weighted voting is our name for Crystal's method of distributing
voting rights to people that add value to the Crystal ecosystem, and
then limiting those voting rights based on if those people meet the core
values of the ecosystem. The measure of whether or not they meet the
values of ecosystem is always the same - their community score.

However, the measure of how much value is being brought into the
ecosystem varies based on whether the stakeholder is an expert or a
client. Experts and clients each get 50\% of the overall voting stake.

\subsubsection{\texorpdfstring{\protect\hypertarget{_ad2r88v0seab}{}{\protect\hypertarget{_Toc462050418}{}{}}EXPERTS}{EXPERTS}}\label{experts}

An expert brings value to the system every time they participate in a
contest- the more expertise an expert has, the more value is added by
them participating in a contest. Experts have 50\% of the vote among all
stakeholders. Relative stake among experts is distributed every time an
expert participates in a contest, and is decided by the amount of
activated reputation tokens that a particular expert has in the
community, the size of the contest relative to all other contests, and
the Affinity score the expert has with that community. The equation for
an individual expert \emph{e}'s relative stake \emph{s} from contest
\emph{c, d} days after the end of the contest is:

{[}needs work, allows for contest spamming (although gas may make that
unprofitable){]}

\[s_{\text{e\ }}(d) = \frac{365(a)}{d} \cdot \frac{t_{c}}{t_{a}} \cdot \ \frac{t_{e}}{t_{t}}\ \]

To break down that equation, we're taking the ratio of tokens in that
contest to average tokens in a contest
(t\textsubscript{c}/t\textsubscript{a}) multiplying that by the ratio of
tokens the expert holds to total tokens in the community
(t\textsubscript{e}/t\textsubscript{t}), multiplying all that by the
experts affinity score to the community (a\textsubscript{e}) and finally
multiplying that by 720 divided by the total number of days since the
contest ended (720/d). This means an expert with an average amount of
tokens and average affinity score participating in an average sized
contest will get a relative stake that steadily decreases towards 1 over
the period of 365 days, and towards 0 over that.

\subsubsection{\texorpdfstring{\protect\hypertarget{_qnpy2c4d2iai}{}{\protect\hypertarget{_Toc462050419}{}{}}CLIENTS}{CLIENTS}}\label{clients}

A client brings value to the system by creating paid contests that
inject money into the system and provide incentives for experts to join
and participate in the platform. Clients have 50\% of the vote among all
stakeholders. They get a stake in the system every time they create a
contest which is then weighted by their Affinity score.

However, these votes are not permanent. Instead, the strength of that
vote decays linearly over time. The relative stake depends on the
difference between the mean fee paid by all Clients in all communities,
and the fee paid by this specific client in this contest. The specific
formula for the relative stake \emph{s} that a client gains from a
contest \emph{c} over time is:

{[}needs work, allows for contest spamming (although gas may make that
unprofitable){]}

\(s_{c}(d) = \frac{365a}{d}(\frac{r_{c}}{r_{a}} + \frac{t_{c}}{t_{a}}\))

Where \emph{a} is the client's affinity score, \emph{r\textsubscript{c
}}is the reward for the contest, \emph{d} is the time in days since the
creation of the contest, and r\textsubscript{a} is the average contest
reward. t\textsubscript{c} is the total amount of tokens in the contest
and t\textsubscript{a} is the average amount of tokens in all contests
in the community. This means that for an average priced contest, with an
average affinity score of.5, with the average amount of tokens owned by
users participating the stake will trend steadily towards 1 over a
period of roughly 365 days, and steadily towards 0 after that. For
average unpaid contests, the period for which it trends towards 1 is
\textasciitilde{}182 days.

\subsection{\texorpdfstring{\protect\hypertarget{_ju4bkmedkcsj}{}{\protect\hypertarget{_Toc462050420}{}{}}REPUTARCHY}{REPUTARCHY}}\label{reputarchy}

Reputarchy is Crystal's name for a governance system which uses
Crystal's reputation and community mechanisms to give decisions to those
communities which have proven they're best at making them. If
futarchy\footnote{http://mason.gmu.edu/\textasciitilde{}rhanson/futarchy.pdf}
is described ``vote on values, bet on beliefs,'' then reputarchy could
be described as ``vote on values, crowdsource beliefs.'' The community
(potentially using value-weighted voting) merely chooses the goals and
values for the upcoming year, and then Crystal's communities hold
contests that determine the best way to meet those values and goals.

\subsubsection{\texorpdfstring{\protect\hypertarget{_hnrexbnydcwo}{}{\protect\hypertarget{_Toc462050421}{}{}}REPUTARCHY
STEP BY STEP}{REPUTARCHY STEP BY STEP}}\label{reputarchy-step-by-step}

Reputarchy follows a three step process, in which the community chooses
a utility function, chooses actions to undertake based on that utility
function, and then implements those actions.

\paragraph{CHOOSING A UTILITY
FUNCTION}\label{choosing-a-utility-function}

A key part of reputarchy is choosing a utility function. There are three
ways that the values and goals in reputarchy could be implemented in a
utility function using Crystal. Firstly, they could be an entirely
subjective set of values and goals described in plain language and voted
on by constituents, given to experts to both interpret and implement
using consensus contests. Secondly they could be an objective set of
metrics voted on by constituents, given to experts to optimize then
measured using objective contests. Thirdly, they could be a subjective
set of metrics combined from constituents using for instance a Likert
Scale, then measured using judging contests.

\paragraph{CHOOSING ACTIONS TO TAKE}\label{choosing-actions-to-take}

Once a utility function is chosen, the next step is to choose a number
of trusted communities known to do good work in a variety of different
disciplines. At regular intervals (weekly, monthly), a contest will be
held in each of these communities, asking ``What's the best thing we
should do around your expertise to maximize our utility?'' The utility
of every idea in every community will be compared, to find the ideas
that have the best chance among all actions in all contests of
fulfilling the organization's utility will be selected

\paragraph{TAKING ACTION }\label{taking-action}

Finally, the actions need to be implemented. Requests for proposal will
be created for each action determined in the previous steps, and the
proposals themselves will be submitted into a Crystal contest. The
proposals can be submitted by traditional contractors, or Crystal
communities themselves, who will crowdsource the work using contests.
All possible proposals will be ranked against their utility in the
utility function, and the money to implement the action will go to the
winner.

\subsubsection{\texorpdfstring{\protect\hypertarget{_1qeh74d4cvuh}{}{\protect\hypertarget{_Toc462050422}{}{}}REPUTARCHY
IN ACTION}{REPUTARCHY IN ACTION}}\label{reputarchy-in-action}

How might a reputarchy might play out in our contract-security
community? To show the flexibility of our utility function standard,
we'll imagine a utility function that combines the three value types
mentioned above.

Let's imagine that the contract-security community votes to have a
utility function with three parts, each of which can be updated every
year. Firstly, the community can choose a measurable key performance
indicator. This year they've chosen their metric to be paid contests
created. Secondly, the community collectively creates and votes on a
mission statement, which this year is ``We aim to be the \#1 ensurer of
contract security in the Ethereum ecosystem''. The performance of this
is measured by the consensus of a group of experts who vote whether ``I
agree that the community met or exceeded its mission.'' Finally, a
value-weighted survey would go to stakeholders in the system at the end
of the year, asking how satisfied they were with the direction of the
community that year. The utility function would then simply multiply all
the answers together like this:

\[utility\  = \ \#\ of\ paid\ contest\ created\  \times \%\ agreement\ that\ community\ met\ mission\  \times Value - weighted\ likert\ \#\]

From there the community would choose a number of trusted expert
communities, who were known to do good work in a variety of areas such
as strategy, programming, marketing, design, etc. Every month, the
community would pay these other expert communities, by creating
campaigns that asked the question ``What project should we do that will
give our utility function the highest value at the end of the year''.
The marketing community might suggest a viral marketing campaign for
their smart-contract auditing platform, the design community might
suggest a redesign of the smart-contract discussion forum, and the
strategy community might suggest launching an entirely new platform that
provides insurance for smart-contract hacks, by estimating the risk of
the hacks then covering losses in case of hacking.

After the contests were completed, the project with the highest overall
utility might be forecasted to be the smart-contract insurance platform.
A request for proposal would be sent out for each of the various actions
needed to launch the platform. The smart-contract community itself might
create a proposal to write the smart-contract backend of the software.
While typically this could be considered a conflict of interest, the
buffer of the utility function means that in fact these types of
accusations can be completely removed. The smart-contract community,
being the world experts in writing smart contracts, would end up winning
the RFP contest.

Finally, the money allocated towards this action would be put towards a
``best backend'' contest, and the backend which was forecasted to best
meet the utility function would be selected among all backends submitted
by participants. The money allocated for this contest would be
distributed to experts relative to how well they performed in the
contest.

\subsubsection{\texorpdfstring{\protect\hypertarget{_l81u909gwhhz}{}{\protect\hypertarget{_Toc462050423}{}{}}USE
CASES OF
REPUTARCHY}{USE CASES OF REPUTARCHY}}\label{use-cases-of-reputarchy}

While reputarchy will likely first be implemented in Crystal
communities, the real power of it comes when other DAOs and traditional
organizations begin to implement it. This will mark a shift at which
organizations will have to be upfront about exactly what they're
optimizing for, and individuals get payed only for their performance.
This will severely limit the ability to play politics within an
organization.

\subsection{\texorpdfstring{\\
CRYSTALDAO}{ CRYSTALDAO}}\label{crystaldao}

The CrystalDAO is the organization which is in charge of running the
central protocol and overseeing the growth and maintenance of the entire
Crystal ecosystem. CrystalDAO plans to start with a stake-weighted
voting governance mechanism, then later switch to a reputarchy
governance mechanism as the ecosystem of expert communities matures.

\subsubsection{\texorpdfstring{\protect\hypertarget{_xf6xygxu22oo}{}{\protect\hypertarget{_Toc462050425}{}{}}MAKING
A PROFIT}{MAKING A PROFIT}}\label{making-a-profit}

CrystalDAO makes money by taking a small cut of the reward from every
paid contest in every community. This reward then goes into the Crystal
smart contract, where it can be used to help fund new communities,
bolster existing communities, create better infrastructure, or be passed
on to vote holders in the form of weekly payments.

\subsubsection{\texorpdfstring{\protect\hypertarget{_uux4chcwr06d}{}{\protect\hypertarget{_Toc462050426}{}{}}REFERRAL
INCENTIVES}{REFERRAL INCENTIVES}}\label{referral-incentives}

Every user on the Crystal platform can receive referral incentives for
referring other active users who add value to the Crystal platform, whom
also get an incentive for signing up under their friend. An active user
is anyone whom has received a vote in Crystal's value-weighted voting
scheme. Once that user receives a vote, both the referrer and the
referred receive a reward of Crystal Clear tokens.

\subsubsection{\texorpdfstring{\protect\hypertarget{_9g2kufwwnfdc}{}{\protect\hypertarget{_Toc462050427}{}{}}CRYSTALDAO
GOVERNANCE
ACTIONS}{CRYSTALDAO GOVERNANCE ACTIONS}}\label{crystaldao-governance-actions}

As the parent organization, CrystalDAO is in charge of taking actions
that cause the ecosystem to flourish. What follows is a list of some of
the most important actions that CrystalDAO can take

\paragraph{SETTING CRYSTAL TOKEN ISSUANCE
RATE}\label{setting-crystal-token-issuance-rate}

Issuance of new tokens in Crystal is set at a steady monthly limit,
which can be tweaked by the stakeholders. This is analogous to a central
bank which is incentivized to maximize the value of the tokens. Newly
issued tokens are split percentage wise among all the communities, and
are created to fuel novice matches and allow the onboarding of new users
into Crystal communities.

\paragraph{SETTING CRYSTAL TOKEN BUY AND BURN
RATE}\label{setting-crystal-token-buy-and-burn-rate}

Just as it may be prudent to issue more tokens in order to onboard more
users onto the platform, it may also make sense to shrink the supply in
order to raise the value of Crystal tokens. For this purpose, the
Crystal has an ongoing offer to buy and burn tokens at a price set by
the DAO. While this price will typically be set to 0, it may be raised
above market value if the supply is growing too fast, in order to
incentivize burning of tokens and shrink the supply.

\paragraph{CHOOSING CORE VALUES}\label{choosing-core-values}

The CrystalDAO is in charge of choosing its own core values. These core
values will in turn determine the value-weight of all votes in the
parent organization, based on those voters' affinity scores with the
organization's core values.

\paragraph{ADDING AND REMOVING MEMBERS FROM THE START
SET}\label{adding-and-removing-members-from-the-start-set}

For each of the core values, the CrystalDAO can choose members whom they
view as paragons of those values, and add them to the start set. If it
comes to light that a person has a different character than previously
assumed, they can be removed from the start set.

\paragraph{SETTING CONTEST FEE}\label{setting-contest-fee}

Every contest on the crystal platform has a small percentage fee taken
from it, which goes to the parent organization. The CrystalDAO sets this
fee at such a level to be competitive, while still allowing maintenance
and growth of the platform.

\paragraph{SETTING STAKE-WEIGHTED
PAYMENTS}\label{setting-stake-weighted-payments}

Every week, a small amount of earnings are taken from the CrystalDAO and
issued to stakeholders, weighted by their stake. The CrystalDAO votes on
this amount.

\paragraph{UPDATING THE PROTOCOL AND GOVERNANCE
RULES}\label{updating-the-protocol-and-governance-rules}

The CrystalDAO is in charge of creating updates to the protocol, as well
as to its own governance rules.

\paragraph{SENDING MONEY}\label{sending-money}

The CrystalDAO can send money to any account on the Ethereum platform.
This may be in payment to a contractor, as a stimulus to an individual
community, or for any other reason.

\subsection{\texorpdfstring{\protect\hypertarget{_lyyxpmxrcjhi}{}{\protect\hypertarget{_Toc462050428}{}{}}COMMUNITY
GOVERNANCE}{COMMUNITY GOVERNANCE}}\label{community-governance}

Communities are places where experts can gather, converse, and work
together to provide value to each other or to clients. Every community
has different goals and purposes, defined by their members and core
values.

\subsubsection{\texorpdfstring{\protect\hypertarget{_p757pudolk1d}{}{\protect\hypertarget{_Toc462050429}{}{}}CREATING
A COMMUNITY}{CREATING A COMMUNITY}}\label{creating-a-community}

Communities are created in stages.

First, the idea for a community is proposed. Potential participants in
the community will begin to interact with each other, tagging each other
with value tags as they discuss the community.

Then, some group of founding members will then initialize the community
by choosing a governance mechanism, and choosing the initial rules for
every aspect of the community. Core values can be chosen by looking at
commonly tagged values between founding members.

From there, a community defined initialization period commences during
which any person can commit Crystal Clear reputation to the system,
turning it into initial reputation for the community at 100\% activation
rate.

After the initialization period, the community starts, and people begin
to start creating and participating in contests. At this point, the
community rules and values can be changed according to the chosen
community governance protocol. Other crystal tokens can enter the
community according to the normal rules.

\subsubsection{\texorpdfstring{\protect\hypertarget{_39dbt8io90sr}{}{\protect\hypertarget{_Toc462050430}{}{}}COMMUNITY
GOVERNANCE
ACTIONS}{COMMUNITY GOVERNANCE ACTIONS}}\label{community-governance-actions}

\paragraph{CHOOSING CORE VALUES}\label{choosing-core-values-1}

The community is in charge of choosing its own core values. These core
values will in turn determine the value-weight of all votes in the
parent organization, based on those voters' affinity scores with the
organization's core values.

\paragraph{ADDING AND REMOVING MEMBERS FROM THE START
SET}\label{adding-and-removing-members-from-the-start-set-1}

For each of the core values, the community can choose members whom they
view as paragons of those values, and add them to the start set. If it
comes to light that a person has a different character than previously
assumed, they can be removed from the start set.

\paragraph{SETTING CONTEST FEE}\label{setting-contest-fee-1}

Every contest in the community has a small percentage fee taken from it,
which goes to the community. The community sets this fee at such a level
to be competitive, while still allowing maintenance and growth of the
community.

\paragraph{CHOOSING PRIVILEGED CONTEST
TYPES}\label{choosing-privileged-contest-types}

Every community chooses some subset of contest types that it considers
privileged. These contest types are allowed to distribute new tokens
through novice matches, and also distribute stake to the CrystalDAO
through participation.

\paragraph{UPDATING CONTESTS AND GOVERNANCE
RULES}\label{updating-contests-and-governance-rules}

The community can choose to update its privileged contests to new
versions, as well as changing its governance contract.

\paragraph{SENDING MONEY}\label{sending-money-1}

The community can send money to any account on the Ethereum platform.
This may be in payment to a contractor, or for any other reason.

\section{\texorpdfstring{\protect\hypertarget{_b8uc7ra9s827}{}{\protect\hypertarget{_Toc462050431}{}{}}USE
CASES}{USE CASES}}\label{use-cases}

\subsection{\texorpdfstring{\protect\hypertarget{_rd5rdlioo2za}{}{\protect\hypertarget{_Toc462050432}{}{}}DECENTRALIZED
APPLICATIONS}{DECENTRALIZED APPLICATIONS}}\label{decentralized-applications}

Decentralized applications (Dapps) have a particular problem that other
applications don't have. They often need to make decisions that require
human judgement, but giving the decision to any one person or small
group of people can end up re-centralizing that app by concentrating
power. With Crystal, all of these human judgements can be made in
decentralized way. For instance, one can \textbf{moderate content}
without a centralized moderator, \textbf{settle user disputes} without a
single company to handle support, \textbf{identify trusted nodes} for
distributed work, and even create \textbf{truth oracles} that provide
trusted data without relying on a single source.

\subsection{\texorpdfstring{\protect\hypertarget{_w8u1x1q8emux}{}{\protect\hypertarget{_Toc462050433}{}{}}RATING
AND GRADING}{RATING AND GRADING}}\label{rating-and-grading}

Ratings and grades are notorious for creating adverse incentives that
cause bad behavior. The centralized review site Yelp has been accused of
extorting business to bury negative reviews\footnote{http://www.huffingtonpost.com/news/yelp-extortion/},
and teachers have been known to give their students the correct answers
on standardized tests\footnote{http://abcnews.go.com/US/atlanta-cheating-178-teachers-administrators-changed-answers-increase/story?id=14013113}.
With Crystal, you can \textbf{democratize education} through
decentralized assessments, create \textbf{cheaper insurance} through
crowdsourced risk assessments, and \textbf{disintermediate review
websites} with reviews and ratings that can't be gamed.

\subsection{\texorpdfstring{\protect\hypertarget{_h2pprzhwlpy8}{}{\protect\hypertarget{_Toc462050434}{}{}}COLLABORATIVE
CROWDSOURCING}{COLLABORATIVE CROWDSOURCING}}\label{collaborative-crowdsourcing}

Anything that can be created by an individual on a computer, can be
created by Crystal crowdsourcing. With Crystal, the things built are
optimized to meet your exact goals or preferences, and are typically
better results than you would receive by contracting a single expert.
You can \textbf{have software reviewed by thousands of reviewers.} You
can create a \textbf{compelling creative book}, and give royalties based
on how much each person contributes. You can even \textbf{design}
\textbf{cars}, \textbf{buildings} or \textbf{organizations}, all at a
cheaper price point, and likely greater quality, than expert work.

\subsection{\texorpdfstring{\protect\hypertarget{_ax6ils45jeyy}{}{\protect\hypertarget{_Toc462050435}{}{}}PORTABLE
REPUTATION}{PORTABLE REPUTATION}}\label{portable-reputation}

With Crystal, you can earn reputation once, and take it everywhere. This
means that \textbf{low quality internet comments will be buried,} as the
best commenters earn their reputation and take it from site to site.
Instead of needing to prove yourself on new \textbf{marketplaces,} you
can take it with you from e.g. Amazon to eBay. Finally, the
\textbf{sharing economy} will be so much safer. Your Uber, Airbnb, and
Snapgoods reputation will all be linked, allowing every user to get a
full measure of the service they will receive.

\subsection{\texorpdfstring{\protect\hypertarget{_bsk46siv4dfd}{}{\protect\hypertarget{_Toc462050436}{}{}}DECISION
MAKING}{DECISION MAKING}}\label{decision-making}

With Crystal, making decisions will be decision-theoretically optimized
according to your goals. Want to get \textbf{individual advice} on
buying shoes that look great and last forever? With Crystal, the crowd
will find the perfect pair for you that balances those two goals.
\textbf{Business strategy} will forever be changed as companies find out
that their CEOs' decisions can be matched or beaten by communities, with
lower price points. Eventually, \textbf{countries} may even jump on the
reputarchy bandwagon.

\subsection{\texorpdfstring{\protect\hypertarget{_5gx0rren5smk}{}{\protect\hypertarget{_Toc462050437}{}{}}FORECASTING}{FORECASTING}}\label{forecasting}

Knowing future possibilities is crucial to wellbeing of millions of
people. Wouldn't it be great to know the likelihood of a major war
springing up in the next year or the chance of an earthquake in
California in the next six months? With Crystal, \textbf{large events,
natural disasters,} and \textbf{existential risks,} can all be given
precise probabilities. These probabilities have been shown to outcompete
even the top forecasting experts\footnote{http://www.npr.org/sections/parallels/2014/04/02/297839429/-so-you-think-youre-smarter-than-a-cia-agent},
and are of similar quality to prediction markets\footnote{http://papers.ssrn.com/sol3/papers.cfm?abstract\_id=2660628}.

\subsection{\texorpdfstring{\protect\hypertarget{_igov4cu3jmvz}{}{\protect\hypertarget{_Toc462050438}{}{}}AI
AUGMENTATION}{AI AUGMENTATION}}\label{ai-augmentation}

Training AI systems to interact with human systems is a common goal, but
the existing approaches suffer from limited training data and poor
specification of human values. Crystal can solve these problems and
create a synergistic effect between AI and humans. Using the Crystal
protocol, for the first time there's an \textbf{API for human
ingenuity}, which communities can be plugged into in order to solve
problems AIs can't. The AIs can then use these \textbf{contests as
training data}, significantly reducing the effort needed to compile such
a data set. Finally, these AIs can be used to further assist humans,
completing the cycle. In general it is assumed that participants in
Crystal communities can be human, AI or humans augmented by AI.

\section{\texorpdfstring{\protect\hypertarget{_nrd1wyttjja6}{}{\protect\hypertarget{_Toc462050439}{}{}}CONCLUSION}{CONCLUSION}}\label{conclusion}

For the first time, Crystal makes possible credible and immutable
reputation metrics that represent the attributes we care about in the
real world. Our value rank algorithm allows any humans' values to be
quantified using the notion of transitive trust. Our Crystal tokens
allow any humans' skills to be quantified using basic decision-theoretic
criteria.

By combining this reputation with a novel method for flexible
crowdsourced contests, we can harness the wisdom of the crowd to out
compete experts. This method has far reaching implications for
governance, decision making, and society at large.

\section{\texorpdfstring{\protect\hypertarget{_4s1munct24fp}{}{\protect\hypertarget{_Toc462050440}{}{}}APPENDIX
A - MATHEMATICAL BUILDING
BLOCKS}{APPENDIX A - MATHEMATICAL BUILDING BLOCKS}}\label{appendix-a---mathematical-building-blocks}

\subsection{\texorpdfstring{\protect\hypertarget{_h8feeor83qgk}{}{\protect\hypertarget{_Toc462050441}{}{}}UTILITY
FUNCTIONS}{UTILITY FUNCTIONS}}\label{utility-functions}

A utility function is a mathematical representation of preferences. In
decision theory, they're central to the concept of making sound
decisions, and for that reason they're the basis of Creativity tokens in
Crystal. One's creativity will be scored based on how well one can
generate options that maximize a given utility function. In addition,
for each input into a utility function, a contest will be created to
earn Accuracy and/or Creativity tokens.

Because there are near limitless representations of utility functions,
Crystal must allow for the possibility of arbitrary complexity. Given
this constraint, each utility function will be its own smart contract on
the Ethereum platform. These smart contracts will have standard
functions, which input any number of variables through a contest format,
and output a number. The higher the number, the more utility received.

Utility functions are hard to grasp for the average users, and we're
actively looking into easy ways to intuitively create utility functions,
including LENS modeling, willingness to pay models, visual equation
builders, and premade utility function libraries. It's also worth noting
that for many applications, utility functions won't have to be created
by the user, as the utility function will be premade by the front-end
dapp, as in our examples with smart-contract security.

\subsection{\texorpdfstring{\protect\hypertarget{_hni0we3evk4r}{}{\protect\hypertarget{_Toc462050442}{}{}}SCORING
RULES AND DIVERGENCE
MEASURS}{SCORING RULES AND DIVERGENCE MEASURS}}\label{scoring-rules-and-divergence-measurs}

A scoring rule is a rule which incentivizes participants to be accurate
to create good forecasts by giving higher score to more accurate
forecasts. A strictly proper scoring rule is any scoring rule in which
incentivizes participants to be honest about their true probabilities,
by giving the highest score to the most accurate predictions. In 2008,
two families of strictly proper scoring rules were found to be able to
incorporate decision-theoretic notions of risk-tolerance,
information-theoretic notions of information gain, and approximate all
of the popular scoring rules\footnote{https://faculty.fuqua.duke.edu/\textasciitilde{}rnau/scoring\_rules\_and\_generalized\_entropy.pdf}.
These constructions were extended to incorporate the property known as
sensitivity-to-distance which allowed forecasters whom were closer to
the correct answer to receive higher scores, as well baseline
distributions, which allowed for the notion of prior information. The
formulas for computing the pseudospherical and power rules with baseline
distribution \emph{q} are as follows:

\emph{Power Rule with Baseline:}
\(S_{\beta}^{P}\left( r,\ e_{j}\left\| q \right.\  \right) = \frac{\left( \frac{r_{j}}{q_{j}} \right)^{\beta - 1} - 1}{\beta - 1} - \frac{\sum_{i = 1}^{n}{({r_{i}\left( \frac{r_{i}}{q_{i}} \right)}^{\beta - 1})}\  - \ 1}{\beta}\)

\emph{Pseudospherical Rule with Baseline:}
\(S_{\beta}^{S}\left( r,\ e_{j}\left\| q \right.\  \right) = \frac{1}{\beta - 1}(\left( \frac{\frac{r_{j}}{q_{j}}}{\left( \sum_{i = 1}^{n}\left( {r_{i}\left( \frac{r_{i}}{q_{i}} \right)}^{\beta - 1} \right) \right)^{\frac{1}{\beta}}} \right)^{\beta - 1}) - 1\)

Where \(\beta\) is any real number, \emph{r} is a reported distribution,
\emph{e} is an event, with \emph{j} being the actual outcome and
\emph{I} being the reported outcome, \emph{n} is the total number of
outcomes, and \emph{q} is the baseline distribution.

Each can be extended to include sensitivity to distance with the
following equations.

\[{\tilde{S}}_{\beta}^{P}(r,\ e_{j}\left\| q \right.\ ) = \sum_{i = 1}^{j - 1}S_{\beta}^{P}(R_{i},e_{2}\left\| Q_{i}) \right.\  + \sum_{i = j}^{n - 1}{S_{\beta}^{P}(R_{i},e_{1}\left\| Q_{i} \right.\ )}\]

\emph{Power rule with baseline and sensitivity to distance.}

The incorporation of a baseline distribution also allows the possibility
for emulation of market scoring rules\footnote{http://mason.gmu.edu/\textasciitilde{}rhanson/mktscore.pdf},
a creation of Robin Hanson which use previous information gained from
forecasters as the baseline.

By incorporating both the discrete and continuous cases of these two
constructions, we can allow every contest to use the scoring rule that
bests suits their needs, whether through a website choosing this option
for their users, or by creating a wizard through which a client can
choose the scoring rule that best fits their needs.

\subsection{\texorpdfstring{\protect\hypertarget{_egxt3ibmcbt9}{}{\protect\hypertarget{_Toc462050443}{}{}}POOLING
ALGORITHM}{POOLING ALGORITHM}}\label{pooling-algorithm}

The pooling algorithm is the algorithm which combines probability
distributions into a single distribution. A pooling algorithm can be as
simple as a weighted average, known as linear pooling, with Accuracy
tokens used for the weight. There are several other algorithms which are
shown to be more accurate by engaging in a process known as extremizing.
An active area of our research is around the tradeoffs to be made in
terms of simplicity, gas costs, and accuracy in the areas of pooling and
bayesian scoring rules.

\subsection{\texorpdfstring{\protect\hypertarget{_555qizcujp4j}{}{\protect\hypertarget{_Toc462050444}{}{}}MONTE
CARLO SIMULATION}{MONTE CARLO SIMULATION}}\label{monte-carlo-simulation}

A Monte-Carlo simulation for our purposes is a way to brute-force input
the results from an aggregated probability distribution into a utility
function. It can then be used to show how different submissions rank in
regards to that utility function. Monte-carlo methods are very
expensive, and it may be that we cannot find a suitable method that also
costs sufficient gas. If this is a case, a ``shadow chain'' will be
used, a concept first described in a blog post by Vitalik
Buterin\footnote{\url{https://blog.ethereum.org/2014/09/17/scalability-part-1-building-top/}}.

\section{ APPENDIX B -- CRYSTAL'S
STANDARDS}\label{appendix-b-crystals-standards}

These are draft versions of Crystal's standards for governance,
reputation, and crowdsourcing standards. We present methods to represent
all our standards in an ABI that can be understood by Ethereum smart
contracts, as well as specified in the resource description framework
(RDF), an XML format which is parsable by computers as well as human
readable. All standards below should be considered drafts, and not
necessarily representative of the final standards.

\subsection{IDENTITY STANDARD}\label{identity-standard}

Crystal's identity standard gives a simple flexible way to map
identities to Ethereum addresses as well as accounts on other websites.
While not mentioned in the whitepaper, its use is critical to
future-proofing Crystal, as a single identity description is not yet
available.

\subsubsection{FUNCTIONS}\label{functions}

\subsubsection{RDF DEFINITION}\label{rdf-definition}

\subsection{REPUTATION STANDARD}\label{reputation-standard}

The Crystal reputation standards defines two standard flavor of
reputations. The first is categorical reputation, which can flexibly
define badges or states that an individual is rated with, and in the
former case can be transformed to work with the Mozilla open badge
standard. The second is numerical reputation, which treats reputation as
a continuous or non-continuous scores. Each smart contract can represent
one ``measure'' of reputation, which can then have multiple hierarchical
``categories'' that the reputation measure can be used in.

For instance, in Crystal's system, the A through F grading system would
be the categorical flavor (with every grade being an optional category
and ``Basic Arithmetic'' might be a general category, with a subcategory

\subsubsection{Functions}\label{functions-1}

\begin{itemize}
\item
  getReputationMinimum
\item
  addReputationCategory(bytes32 parentID, bytes32 rephash, bytes32 URL)
  returns (bytes32 ID);
\end{itemize}

\begin{quote}
adds a new category
\end{quote}

\begin{itemize}
\item
  parentID is the id of the parent. 0 means no parent.
\item
  RDFhash represents the hash of the reputation information, represented
  in Crystal's RDF reputation format.
\item
  URI represents the link at which you can access the full RDF
  description, which could be an IPFS link, a standard web link, or data
  stored in the smart contract)
\end{itemize}

\subsection{TOKEN TO REPUTATION MAPPING
STANDARD}\label{token-to-reputation-mapping-standard}

\subsection{CONTEST STANDARD}\label{contest-standard-1}

\subsection{GOVERNANCE STANDARD}\label{governance-standard-1}

\subsection{UTILITY FUNCTION STANDARD}\label{utility-function-standard}
